{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#importation des données\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "REgd8WV-6rDR",
        "outputId": "6a4f698d-d0a5-4ab4-a4dc-c9fd86288644"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6269d9e1-aef9-4a6a-82a0-66bafcaf725e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6269d9e1-aef9-4a6a-82a0-66bafcaf725e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Fake.csv to Fake.csv\n",
            "Saving True.csv to True.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "CPhYFu_M69bW",
        "outputId": "ae4494ac-9ff8-4d3e-ebee-a7e55d922878"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-91ffd2ae-2c64-47f6-bed8-5967833e822d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-91ffd2ae-2c64-47f6-bed8-5967833e822d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Fake.csv to Fake.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "PX_AJaKn6pDT",
        "outputId": "4573b5ef-93df-4ab8-a5c2-accfef5e210a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-1668f1dcdf0f>:23: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  fake['title'] = fake['title'].str.replace('[^\\w\\s]', '')\n",
            "<ipython-input-7-1668f1dcdf0f>:24: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  fake['text'] = fake['text'].str.replace('[^\\w\\s]', '')\n",
            "<ipython-input-7-1668f1dcdf0f>:25: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  true['title'] = true['title'].str.replace('[^\\w\\s]', '')\n",
            "<ipython-input-7-1668f1dcdf0f>:26: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  true['text'] = true['text'].str.replace('[^\\w\\s]', '')\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           able  absolutely    access  according  account   accused    across  \\\n",
              "0      0.000000         0.0  0.000000   0.000000      0.0  0.000000  0.000000   \n",
              "1      0.000000         0.0  0.000000   0.000000      0.0  0.000000  0.000000   \n",
              "2      0.000000         0.0  0.000000   0.000000      0.0  0.000000  0.000000   \n",
              "3      0.000000         0.0  0.000000   0.048465      0.0  0.065157  0.000000   \n",
              "4      0.000000         0.0  0.000000   0.128467      0.0  0.000000  0.000000   \n",
              "...         ...         ...       ...        ...      ...       ...       ...   \n",
              "44893  0.055686         0.0  0.000000   0.000000      0.0  0.000000  0.000000   \n",
              "44894  0.000000         0.0  0.097263   0.000000      0.0  0.000000  0.000000   \n",
              "44895  0.000000         0.0  0.000000   0.015177      0.0  0.010202  0.009703   \n",
              "44896  0.000000         0.0  0.000000   0.000000      0.0  0.000000  0.000000   \n",
              "44897  0.000000         0.0  0.000000   0.086871      0.0  0.000000  0.000000   \n",
              "\n",
              "            act    action   actions  ...     would  wrong     wrote      year  \\\n",
              "0      0.000000  0.038189  0.000000  ...  0.054611    0.0  0.000000  0.000000   \n",
              "1      0.000000  0.000000  0.000000  ...  0.139130    0.0  0.000000  0.000000   \n",
              "2      0.000000  0.000000  0.000000  ...  0.025155    0.0  0.000000  0.035875   \n",
              "3      0.000000  0.000000  0.072496  ...  0.030628    0.0  0.000000  0.043680   \n",
              "4      0.000000  0.000000  0.000000  ...  0.016237    0.0  0.034621  0.115783   \n",
              "...         ...       ...       ...  ...       ...    ...       ...       ...   \n",
              "44893  0.106865  0.000000  0.126062  ...  0.079887    0.0  0.000000  0.000000   \n",
              "44894  0.000000  0.000000  0.000000  ...  0.000000    0.0  0.000000  0.000000   \n",
              "44895  0.009623  0.000000  0.000000  ...  0.067141    0.0  0.000000  0.006840   \n",
              "44896  0.000000  0.000000  0.000000  ...  0.050837    0.0  0.000000  0.036250   \n",
              "44897  0.036719  0.000000  0.000000  ...  0.036599    0.0  0.000000  0.026098   \n",
              "\n",
              "       yearold     years       yet      york     young  class  \n",
              "0          0.0  0.078563  0.035196  0.000000  0.041691      1  \n",
              "1          0.0  0.000000  0.000000  0.000000  0.000000      1  \n",
              "2          0.0  0.000000  0.000000  0.093637  0.000000      1  \n",
              "3          0.0  0.000000  0.000000  0.171015  0.000000      1  \n",
              "4          0.0  0.000000  0.000000  0.000000  0.000000      1  \n",
              "...        ...       ...       ...       ...       ...    ...  \n",
              "44893      0.0  0.000000  0.000000  0.049562  0.000000      0  \n",
              "44894      0.0  0.000000  0.000000  0.000000  0.000000      0  \n",
              "44895      0.0  0.041395  0.009272  0.017852  0.000000      0  \n",
              "44896      0.0  0.000000  0.000000  0.000000  0.000000      0  \n",
              "44897      0.0  0.000000  0.000000  0.000000  0.000000      0  \n",
              "\n",
              "[44898 rows x 1001 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-db570cc7-7cb6-455b-b4dd-8bd436ea5ceb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>able</th>\n",
              "      <th>absolutely</th>\n",
              "      <th>access</th>\n",
              "      <th>according</th>\n",
              "      <th>account</th>\n",
              "      <th>accused</th>\n",
              "      <th>across</th>\n",
              "      <th>act</th>\n",
              "      <th>action</th>\n",
              "      <th>actions</th>\n",
              "      <th>...</th>\n",
              "      <th>would</th>\n",
              "      <th>wrong</th>\n",
              "      <th>wrote</th>\n",
              "      <th>year</th>\n",
              "      <th>yearold</th>\n",
              "      <th>years</th>\n",
              "      <th>yet</th>\n",
              "      <th>york</th>\n",
              "      <th>young</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.038189</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.054611</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.078563</td>\n",
              "      <td>0.035196</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.041691</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.139130</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.025155</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.035875</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.093637</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.048465</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.065157</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.072496</td>\n",
              "      <td>...</td>\n",
              "      <td>0.030628</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.043680</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.171015</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.128467</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.016237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.034621</td>\n",
              "      <td>0.115783</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44893</th>\n",
              "      <td>0.055686</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.106865</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.126062</td>\n",
              "      <td>...</td>\n",
              "      <td>0.079887</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.049562</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44894</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.097263</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44895</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.015177</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.010202</td>\n",
              "      <td>0.009703</td>\n",
              "      <td>0.009623</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.067141</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006840</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.041395</td>\n",
              "      <td>0.009272</td>\n",
              "      <td>0.017852</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44896</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.050837</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.036250</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44897</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.086871</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.036719</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.036599</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.026098</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>44898 rows × 1001 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-db570cc7-7cb6-455b-b4dd-8bd436ea5ceb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-db570cc7-7cb6-455b-b4dd-8bd436ea5ceb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-db570cc7-7cb6-455b-b4dd-8bd436ea5ceb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import scipy\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "#on transforme nos datasets en dataframes\n",
        "true = pd.read_csv(\"True.csv\")\n",
        "fake = pd.read_csv(\"Fake.csv\")\n",
        "\n",
        "true['class'] = 1\n",
        "fake['class'] = 0\n",
        "fake['title'] = fake['title'].str.lower()\n",
        "fake['text'] = fake['text'].str.lower()\n",
        "true['title'] = true['title'].str.lower()\n",
        "true['text'] = true['text'].str.lower()\n",
        "fake['title'] = fake['title'].str.replace('[^\\w\\s]', '')\n",
        "fake['text'] = fake['text'].str.replace('[^\\w\\s]', '')\n",
        "true['title'] = true['title'].str.replace('[^\\w\\s]', '')\n",
        "true['text'] = true['text'].str.replace('[^\\w\\s]', '')\n",
        "true['combined_text'] = true['title'] + ' ' + true['text']\n",
        "fake['combined_text'] = fake['title'] + ' ' + fake['text']\n",
        "dataset=pd.concat([true, fake])\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "def remove_stop_words(text):\n",
        "    words = text.split()\n",
        "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "    return ' '.join(filtered_words)\n",
        "# Function to remove numbers from a string\n",
        "def remove_numbers(text):\n",
        "    return re.sub(r'\\d+', '', text)\n",
        "# Fonction pour garder uniquement les lettres et les espaces\n",
        "def keep_letters_and_spaces(text):\n",
        "    return re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "dataset['final_text'] = dataset['combined_text'].apply(remove_stop_words)\n",
        "dataset['final_text2'] = dataset['final_text'].apply(remove_numbers)\n",
        "dataset['final_text3'] = dataset['final_text2'].apply(keep_letters_and_spaces)\n",
        "df = dataset[['final_text3','class']].copy()\n",
        "\n",
        "\n",
        "max_features_value=1000\n",
        "tfidf = TfidfVectorizer(max_features=max_features_value)\n",
        "tfidf.fit(df['final_text3'])\n",
        "tfidf_features = tfidf.transform(df['final_text3'])\n",
        "\n",
        "tfidf_features_sparse = csr_matrix(tfidf_features)\n",
        "tfidf_df = pd.DataFrame.sparse.from_spmatrix(tfidf_features_sparse, columns=tfidf.get_feature_names_out())\n",
        "\n",
        "column_name = 'class'\n",
        "tfidf_df[column_name] = df[column_name].values\n",
        "\n",
        "df['len']=df['final_text3'].str.len()\n",
        "df['num']=df['final_text3'].str.split().map(lambda x: len(x))\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "column_name = 'len'\n",
        "column_name2 = 'num'\n",
        "\n",
        "df[column_name] = scaler.fit_transform(df[[column_name]])\n",
        "df[column_name2] = scaler.fit_transform(df[[column_name2]])\n",
        "\n",
        "\n",
        "tfidf_df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Modèle 1 : Random Forest\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# On sépare les données en caractéristiques et classe\n",
        "X = tfidf_df.drop('class', axis=1)\n",
        "y = tfidf_df['class']\n",
        "\n",
        "# On définit les mesures de performance MAE, RMSE, MAPE et R^2\n",
        "def evaluation_performance_RF(y_true, y_pred):\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    return accuracy, mae, rmse, r2\n",
        "\n",
        "# On définit les paramètres du Random Forest\n",
        "n_estimators = 100\n",
        "max_depth = None\n",
        "\n",
        "# On définit le nombre de folds pour la cross-validation\n",
        "n_splits = 5\n",
        "kf = KFold(n_splits=n_splits, shuffle=True)\n",
        "\n",
        "accuracy_scores_RF = []\n",
        "mae_scores_RF = []\n",
        "rmse_scores_RF = []\n",
        "r2_scores_RF = []\n",
        "\n",
        "# On lance la cross-validation\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # On créé et on ajuste le modèle Random Forest\n",
        "    rf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth)\n",
        "    rf.fit(X_train, y_train)\n",
        "\n",
        "    # On lance la prédiction sur l'ensemble de test\n",
        "    y_pred = rf.predict(X_test)\n",
        "\n",
        "    # On procède à l'évaluation des performances\n",
        "    accuracy, mae, rmse, r2 = evaluation_performance_RF(y_test, y_pred)\n",
        "\n",
        "    accuracy_scores_RF.append(accuracy)\n",
        "    mae_scores_RF.append(mae)\n",
        "    rmse_scores_RF.append(rmse)\n",
        "    r2_scores_RF.append(r2)\n",
        "\n",
        "\n",
        "# On calcule la moyenne des scores de performance\n",
        "moy_accuracy_RF = np.mean(accuracy_scores_RF)\n",
        "moy_mae_RF = np.mean(mae_scores_RF)\n",
        "moy_rmse_RF = np.mean(rmse_scores_RF)\n",
        "moy_r2_RF = np.mean(r2_scores_RF)\n",
        "\n",
        "print(\"Random Forest : \")\n",
        "print(\"Accuracy : \", moy_accuracy_RF)\n",
        "print(\"MAE : \", moy_mae_RF)\n",
        "print(\"RMSE : \", moy_rmse_RF)\n",
        "print(\"R² : \", moy_r2_RF)\n"
      ],
      "metadata": {
        "id": "uh0ubaMJ7FOt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7455bfc6-3fb2-465a-c746-324d5f574908"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest : \n",
            "Accuracy :  0.9974608905560636\n",
            "MAE :  0.002539109443936371\n",
            "RMSE :  0.05016010308500689\n",
            "R² :  0.9898223897628078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Modèle 2 : Decision tree\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# On sépare les données en caractéristiques et classe\n",
        "X = tfidf_df.drop('class', axis=1)\n",
        "y = tfidf_df['class']\n",
        "\n",
        "# On définit les mesures de performance MAE, RMSE, MAPE et R^2\n",
        "def evaluation_performance_DT(y_true, y_pred):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    return accuracy, mae, rmse, r2\n",
        "\n",
        "# On définit les paramètres de l'arbre de décision\n",
        "max_depth = None\n",
        "\n",
        "# On définit le nombre de folds pour la cross-validation\n",
        "n_splits = 5\n",
        "kf = KFold(n_splits=n_splits, shuffle=True)\n",
        "\n",
        "accuracy_scores_DT = []\n",
        "mae_scores_DT = []\n",
        "rmse_scores_DT = []\n",
        "r2_scores_DT = []\n",
        "\n",
        "#On lance la cross-validation\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # On créé et on ajuste le modèle d'arbre de décision\n",
        "    dt = DecisionTreeClassifier(max_depth=max_depth)\n",
        "    dt.fit(X_train, y_train)\n",
        "\n",
        "    # On lance la prédiction sur l'ensemble de test\n",
        "    y_pred = dt.predict(X_test)\n",
        "\n",
        "    # On procéde à l'évaluation des performances\n",
        "    accuracy, mae, rmse, r2 = evaluation_performance_DT(y_test, y_pred)\n",
        "\n",
        "    accuracy_scores_DT.append(accuracy)\n",
        "    mae_scores_DT.append(mae)\n",
        "    rmse_scores_DT.append(rmse)\n",
        "    r2_scores_DT.append(r2)\n",
        "\n",
        "# On calcule la moyenne des scores de performance\n",
        "avg_accuracy_DT = np.mean(accuracy_scores_DT)\n",
        "avg_mae_DT = np.mean(mae_scores_DT)\n",
        "avg_rmse_DT = np.mean(rmse_scores_DT)\n",
        "avg_r2_DT = np.mean(r2_scores_DT)\n",
        "\n",
        "print(\"Arbre de décision :\")\n",
        "print(\"Accuracy : \", avg_accuracy_DT)\n",
        "print(\"MAE : \", avg_mae_DT)\n",
        "print(\"RMSE : \", avg_rmse_DT)\n",
        "print(\"R² : \", avg_r2_DT)\n"
      ],
      "metadata": {
        "id": "rxuDoGNm7JeP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36766ad6-790b-453a-e2a6-637786a8db34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arbre de décision :\n",
            "Accuracy :  0.9950331843343451\n",
            "MAE :  0.004966815665654901\n",
            "RMSE :  0.07023331142065957\n",
            "R² :  0.9800901831559834\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Modèle 3 : SVM\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# On sépare les données en caractéristiques et classe\n",
        "X = tfidf_df.drop('class', axis=1)\n",
        "y = tfidf_df['class']\n",
        "\n",
        "# On définit les mesures de performance MAE, RMSE, MAPE et R^2\n",
        "def evaluate_performance_SVM(y_true, y_pred):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    return accuracy, mae, rmse, r2\n",
        "\n",
        "# On définit les paramètres de SVM\n",
        "C = 1.0\n",
        "kernel = 'rbf'\n",
        "\n",
        "# On définit le nombre de folds pour la cross-validation\n",
        "n_splits = 2\n",
        "kf = KFold(n_splits=n_splits, shuffle=True)\n",
        "\n",
        "accuracy_scores_SVM = []\n",
        "mae_scores_SVM = []\n",
        "rmse_scores_SVM = []\n",
        "r2_scores_SVM = []\n",
        "\n",
        "# On lance la boucle de cross-validation\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # On créé et ajusteme le modèle SVM\n",
        "    svm = SVC(C=C, kernel=kernel)\n",
        "    svm.fit(X_train.values, y_train.values)  # Utilisation de .values pour convertir en tableaux NumPy\n",
        "\n",
        "    # On lance la prédiction sur l'ensemble de test\n",
        "    y_pred = svm.predict(X_test.values)  # Utilisation de .values pour convertir en tableaux NumPy\n",
        "\n",
        "    # On lance l'évaluation des performances\n",
        "    accuracy, mae, rmse, r2 = evaluate_performance_SVM(y_test.values, y_pred)  # Utilisation de .values pour convertir en tableaux NumPy\n",
        "\n",
        "    accuracy_scores_SVM.append(accuracy)\n",
        "    mae_scores_SVM.append(mae)\n",
        "    rmse_scores_SVM.append(rmse)\n",
        "    r2_scores_SVM.append(r2)\n",
        "\n",
        "# On calcule la moyenne des scores de performance\n",
        "avg_accuracy_SVM = np.mean(accuracy_scores_SVM)\n",
        "avg_mae_SVM = np.mean(mae_scores_SVM)\n",
        "avg_rmse_SVM = np.mean(rmse_scores_SVM)\n",
        "avg_r2_SVM = np.mean(r2_scores_SVM)\n",
        "\n",
        "print(\"SVM :\")\n",
        "print(\"Accuracy : \", avg_accuracy_SVM)\n",
        "print(\"MAE : \", avg_mae_SVM)\n",
        "print(\"RMSE : \", avg_rmse_SVM)\n",
        "print(\"R² : \", avg_r2_SVM)\n"
      ],
      "metadata": {
        "id": "fUf29ORRXuAa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ec647d8-342a-4631-cee0-d0841971b8d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM :\n",
            "Accuracy :  0.9921600071272663\n",
            "MAE :  0.007839992872733752\n",
            "RMSE :  0.08845202617073675\n",
            "R² :  0.9685670427302947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pad_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQ4ZHRk3qtqS",
        "outputId": "c8b1bb46-15d1-468d-ff92-421aba3e3d78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pad_sequences\n",
            "  Downloading pad-sequences-0.6.1.tar.gz (9.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pad_sequences\n",
            "  Building wheel for pad_sequences (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pad_sequences: filename=pad_sequences-0.6.1-py3-none-any.whl size=10199 sha256=326cbe875dbf1ef0711f9c3ef77c460de336dd50e6b3b981eaf1eb52327eb678\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/9d/22/0a6305b87a9cc46ccc032060a041c3b59f39ac462f7358997e\n",
            "Successfully built pad_sequences\n",
            "Installing collected packages: pad_sequences\n",
            "Successfully installed pad_sequences-0.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Modèle 4 : LSTM\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Dense, LSTM, Bidirectional\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# On sépare les données en caractéristiques et classe\n",
        "X = tfidf_df.drop('class', axis=1)\n",
        "y = tfidf_df['class']\n",
        "\n",
        "# On définit des paramètres du modèle\n",
        "vocab_size = max_features_value\n",
        "embedding_dim = 40\n",
        "max_length = 100\n",
        "\n",
        "# On convertit les phrases en séquences d'entiers\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(df['final_text3'])\n",
        "sequences = tokenizer.texts_to_sequences(df['final_text3'])\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post', truncating='post')\n",
        "\n",
        "# On procède à la division des données en ensembles d'entraînement et de test\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# On créé le modèle LSTM\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim, input_length=max_length))\n",
        "model.add(Bidirectional(LSTM(32, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(32)))\n",
        "model.add(Dense(24, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# On lance la compilation du modèle\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# On lance l'entraînement du modèle\n",
        "num_epochs = 10\n",
        "history = model.fit(X_train, y_train, epochs=num_epochs, validation_data=(X_test, y_test), verbose=2)\n",
        "\n",
        "# On fait les prédictions sur les données de test\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# On calcule les mesures de performance\n",
        "accuracy = accuracy_score(y_test, np.round(y_pred))\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"LSTM\")\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"MAE: \", mae)\n",
        "print(\"RMSE: \", rmse)\n",
        "print(\"R²: \", r2)"
      ],
      "metadata": {
        "id": "VTwwoeop7MPE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8972b860-cd8b-412a-9298-db45d9882308"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1123/1123 - 222s - loss: 0.0437 - accuracy: 0.9798 - val_loss: 0.0185 - val_accuracy: 0.9967 - 222s/epoch - 197ms/step\n",
            "Epoch 2/10\n",
            "1123/1123 - 217s - loss: 0.0076 - accuracy: 0.9985 - val_loss: 0.0135 - val_accuracy: 0.9973 - 217s/epoch - 193ms/step\n",
            "Epoch 3/10\n",
            "1123/1123 - 218s - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.0119 - val_accuracy: 0.9970 - 218s/epoch - 194ms/step\n",
            "Epoch 4/10\n",
            "1123/1123 - 219s - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0115 - val_accuracy: 0.9973 - 219s/epoch - 195ms/step\n",
            "Epoch 5/10\n",
            "1123/1123 - 216s - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.0123 - val_accuracy: 0.9977 - 216s/epoch - 192ms/step\n",
            "Epoch 6/10\n",
            "1123/1123 - 217s - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0180 - val_accuracy: 0.9977 - 217s/epoch - 193ms/step\n",
            "Epoch 7/10\n",
            "1123/1123 - 220s - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0150 - val_accuracy: 0.9977 - 220s/epoch - 196ms/step\n",
            "Epoch 8/10\n",
            "1123/1123 - 215s - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0187 - val_accuracy: 0.9972 - 215s/epoch - 191ms/step\n",
            "Epoch 9/10\n",
            "1123/1123 - 215s - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0159 - val_accuracy: 0.9973 - 215s/epoch - 192ms/step\n",
            "Epoch 10/10\n",
            "1123/1123 - 206s - loss: 8.8672e-04 - accuracy: 0.9997 - val_loss: 0.0166 - val_accuracy: 0.9976 - 206s/epoch - 183ms/step\n",
            "281/281 [==============================] - 14s 43ms/step\n",
            "LSTM\n",
            "Accuracy: 0.9975501113585746\n",
            "MAE:  0.0024333090893865444\n",
            "RMSE:  0.04729786262293804\n",
            "R²:  0.9910402713884846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Modèle 5 : CNN\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense, LSTM, Bidirectional, Conv1D, GlobalMaxPooling1D, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming you have a Pandas DataFrame called 'df' with 1001 columns\n",
        "\n",
        "shuffled_df = tfidf_df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Convert DataFrame to numpy array\n",
        "data = shuffled_df.to_numpy()\n",
        "\n",
        "# Split the data into input features (X) and target variable (y)\n",
        "X = data[:, :1000]  # Assuming the first 1000 columns are input features\n",
        "y = data[:, 1000]  # Assuming the last column is the target variable\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define other necessary variables\n",
        "embedding_dim = 100\n",
        "num_filters = 128\n",
        "dropout_rate = 0.2\n",
        "\n",
        "# Create the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=10000, output_dim=embedding_dim, input_length=1000))  # Assuming vocabulary size is 10000\n",
        "model.add(Conv1D(filters=num_filters, kernel_size=3, activation='relu'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(dropout_rate))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "print(model.summary())\n",
        "num_epochs = 10\n",
        "history = model.fit(X_train, y_train, epochs=num_epochs, validation_data=(X_test, y_test), verbose=2)\n",
        "# Évaluez le modèle sur l'ensemble de test\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Prédire les valeurs sur l'ensemble de test\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error, r2_score\n",
        "# On calcule les mesures de performance\n",
        "accuracy = accuracy_score(y_test, np.round(y_pred))\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"CNN\")\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"MAE: \", mae)\n",
        "print(\"RMSE: \", rmse)\n",
        "print(\"R²: \", r2)"
      ],
      "metadata": {
        "id": "sz7JEjqgh57X",
        "outputId": "e51f1426-4c3e-4a09-a9f9-538bed43942c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 1000, 100)         1000000   \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 998, 128)          38528     \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 128)              0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,055,169\n",
            "Trainable params: 1,055,169\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "1123/1123 - 168s - loss: 0.6923 - accuracy: 0.5236 - val_loss: 0.6923 - val_accuracy: 0.5205 - 168s/epoch - 150ms/step\n",
            "Epoch 2/10\n",
            "1123/1123 - 158s - loss: 0.6920 - accuracy: 0.5235 - val_loss: 0.6921 - val_accuracy: 0.5205 - 158s/epoch - 141ms/step\n",
            "Epoch 3/10\n",
            "1123/1123 - 160s - loss: 0.6918 - accuracy: 0.5236 - val_loss: 0.6920 - val_accuracy: 0.5205 - 160s/epoch - 143ms/step\n",
            "Epoch 4/10\n",
            "1123/1123 - 161s - loss: 0.6918 - accuracy: 0.5236 - val_loss: 0.6921 - val_accuracy: 0.5205 - 161s/epoch - 143ms/step\n",
            "Epoch 5/10\n",
            "1123/1123 - 159s - loss: 0.6918 - accuracy: 0.5236 - val_loss: 0.6921 - val_accuracy: 0.5205 - 159s/epoch - 142ms/step\n",
            "Epoch 6/10\n",
            "1123/1123 - 161s - loss: 0.6919 - accuracy: 0.5236 - val_loss: 0.6921 - val_accuracy: 0.5205 - 161s/epoch - 143ms/step\n",
            "Epoch 7/10\n",
            "1123/1123 - 159s - loss: 0.6918 - accuracy: 0.5236 - val_loss: 0.6922 - val_accuracy: 0.5205 - 159s/epoch - 142ms/step\n",
            "Epoch 8/10\n",
            "1123/1123 - 162s - loss: 0.6918 - accuracy: 0.5236 - val_loss: 0.6920 - val_accuracy: 0.5205 - 162s/epoch - 144ms/step\n",
            "Epoch 9/10\n",
            "1123/1123 - 160s - loss: 0.6918 - accuracy: 0.5236 - val_loss: 0.6920 - val_accuracy: 0.5205 - 160s/epoch - 142ms/step\n",
            "Epoch 10/10\n",
            "1123/1123 - 160s - loss: 0.6918 - accuracy: 0.5236 - val_loss: 0.6921 - val_accuracy: 0.5205 - 160s/epoch - 142ms/step\n",
            "Accuracy: 0.5204899907112122\n",
            "281/281 [==============================] - 11s 37ms/step\n",
            "CNN\n",
            "Accuracy: 0.5204899777282851\n",
            "MAE:  0.49864910103349447\n",
            "RMSE:  0.499534552648372\n",
            "R²:  0.00018187151950477265\n"
          ]
        }
      ]
    }
  ]
}